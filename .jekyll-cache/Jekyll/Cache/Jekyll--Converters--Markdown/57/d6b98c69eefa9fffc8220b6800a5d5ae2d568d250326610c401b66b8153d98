I"f<h2 id="current-position">Current Position</h2>
<p>I am a research Scientist at Samsung SAIL Montreal, in the MILA, headed by <a href="http://www.iro.umontreal.ca/~slacoste/">Simon Lacoste-Julien</a>. I focus my research on optimization for machine learning, especially accelerated and adaptive methods. I work closely with researchers from Montreal and McGill Universities.</p>

<hr />

<h2 id="research-interests">Research interests</h2>
<p>My main research interest is <strong>convex optimization (deterministic or stochastic)</strong>, but I am also interested in <strong>numerical analysis</strong>. Here is a non-exhaustive selection of topics:</p>
<ul>
  <li><em>Average-case Analysis for Optimization Algorithms</em></li>
  <li><em>Generic Acceleration Methods and Multisecant Quasi-Newton Methods</em>,</li>
  <li><em>Algorithms for Variational Inequalities</em></li>
  <li><em>Integration Algorithms for ODE</em> (and their links with optimization).</li>
</ul>

<h2 id="prior-positions">Prior positions</h2>

<h3 id="post-doc-princeton-cs-department">Post-doc (Princeton CS Department)</h3>
<p>I worked one year at Princeton University in the CS department with <a href="https://www.cs.princeton.edu/~ehazan/">Elad Hazan</a> and <a href="https://www.cs.princeton.edu/~arora/">Sanjeev Arora</a>. I collaborated with other researchers in ORFE (<a href="https://sjelassi.github.io/">Samy Jelassi</a> and <a href="https://www.linkedin.com/in/thomas-pumir-ab77b936/">Thomas Pumir</a>), as well as with <a href="https://web.math.princeton.edu/~nboumal/">Nicolas Boumal</a> from the PACM. I worked on multisecant Quasi-Newton methods and stochastic algorithms for game theory.</p>

<h3 id="phd-studies-inriaens">PhD Studies (INRIA/ENS)</h3>
<p>I am a former Ph.D. Student (from 2015 to 2018) of <a href="http://www.di.ens.fr/~aspremon/">Alexandre dâ€™Aspremont</a> and <a href="http://www.di.ens.fr/~fbach">Francis Bach</a>. I worked in the Sierra Team, part of the <a href="http://www.di.ens.fr/">Computer Science Department</a> of <a href="http://www.ens.fr/en">Ã‰cole Normale SupÃ©rieure Ulm</a>. I also earned the <a href="https://espaces-numeriques.org/prix-de-these-psl-adeli-2019/">best thesis in data science award from PSD University</a></p>

<p>My thesis, <a href="https://hal.archives-ouvertes.fr/tel-01887163/document">Acceleration in Optimisation</a>, focuses on links between acceleration and numerical analysis. The main contribution is the design of the algorithm <a href="https://arxiv.org/abs/1805.09639">Regularized Nonlinear Acceleration</a> - a generic way to improve the rate of convergence of many optimization methods.</p>

<h3 id="master-studies-ucl">Master Studies (UCL)</h3>
<p>I did my master thesis in optimization with my advisor <a href="https://scholar.google.com/citations?user=DJ8Ep8YAAAAJ">Yurii Nesterov</a>. I graduated from <a href="https://uclouvain.be/fr/facultes/epl">Ã‰cole Polytechnique de Louvain</a> in 2015 and got a masterâ€™s degree in Mathematical Engineering. 
At UCL, I also collaborated with <a href="https://people.stanford.edu/lcambier/">Leopold Cambier</a> and <a href="http://perso.uclouvain.be/anthony.papavasiliou/public_html/">Anthony Papavasiliou</a> for the creation of the <a href="https://web.stanford.edu/~lcambier/fast/">FAST toolbox</a>. 
In the same time, I worked with <a href="http://perso.uclouvain.be/raphael.jungers/content/home">Raphael Jungers</a> and <a href="https://perso.uclouvain.be/julien.hendrickx/">Julien Hendrickx</a> in the context of the <a href="http://fr.mathworks.com/matlabcentral/fileexchange/33202-the-jsr-toolbox">JSR Toolbox</a>.</p>

<h2 id="external-links">External Links</h2>
<ul>
  <li><a href="https://github.com/windows7lover">Github</a></li>
  <li><a href="https://scholar.google.fr/citations?user=hNscQzgAAAAJ&amp;hl=fr">Google Scholar</a></li>
  <li><a href="https://www.linkedin.com/in/damien-scieur-6873ba82/">LinkedIn</a></li>
</ul>
:ET